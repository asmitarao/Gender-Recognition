# -*- coding: utf-8 -*-
"""save_svm.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13dG0cT-D19-GIj3O2dCM-ydR70scWy-V
"""

#change the data folder and run

import numpy as np
import keras.utils
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers.normalization import BatchNormalization
from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten,Activation
from keras.layers import Conv2D,MaxPooling2D#use 2d convo layers because filter goes horizontal and vertical
from keras.activations import relu
import keras.losses
import pandas
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
import pickle
import os
import glob
import cv2
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from keras.optimizers import SGD
from sklearn.svm import SVC

train_folder = 'testData'

train_set = []
train_y = []
for filename in os.listdir(train_folder):
	#female -1 and male - 0
	

	if(filename[-34] == '1'):
		train_y.append(1)
	else:
		train_y.append(0)
	filename = train_folder+'/'+filename
	train_set.append(cv2.imread(filename))

xTrain, xTest, yTrain, yTest = train_test_split(train_set, train_y, test_size = 0.2, random_state = 0)
epochs = 90
train_set = np.array(xTrain)
train_y  = np.array(yTrain)

test_set = np.array(xTest)
test_y  = np.array(yTest)


model = Sequential()

model.add(Conv2D(96,kernel_size=7,strides=(4,4),input_shape=(227,227,3),padding='valid',data_format="channels_last"))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
model.add(BatchNormalization())

model.add(Conv2D(256,kernel_size=5,padding='valid'))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
model.add(BatchNormalization())

model.add(Conv2D(384,kernel_size=3,padding='valid'))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))

model.add(Flatten(name="layer_f"))

model.add(Dense(512,name="layer_x"))
model.add(Activation("relu"))
model.add(Dropout(0.3))

model.add(Dense(512))
model.add(Activation("relu"))
model.add(Dropout(0.3))

model.add(Dense(1,activation='sigmoid'))
model.summary()

model.compile(loss = 'hinge',optimizer = keras.optimizers.SGD(lr=0.002),metrics=['accuracy'])

train = model.fit(train_set,train_y,epochs = epochs,verbose = 1,validation_data = (test_set,test_y))

model_feat = Model(inputs=model.input,outputs=model.get_layer('layer_f').output)

feat_train = model_feat.predict(train_set)
feat_test = model_feat.predict(test_set)

svm = SVC(kernel='rbf')

svm.fit(feat_train,train_y)

filename = 'drive/My Drive/finalized_model.sav'
pickle.dump(svm, open(filename, 'wb'))


pred = svm.predict(feat_test)

print(accuracy_score(test_y, pred))


#mode3 is where we are saving the model using pickle
# serialize model to JSON
model_json = model_feat.to_json()
with open("model4.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model_feat.save_weights("model4.h5")

#model with just svm
import numpy as np
import keras.utils
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers.normalization import BatchNormalization
from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten,Activation
from keras.layers import Conv2D,MaxPooling2D#use 2d convo layers because filter goes horizontal and vertical
from keras.activations import relu
import keras.losses
import pandas
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
import pickle
import os
import glob
import cv2
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from keras.optimizers import SGD
from sklearn.svm import SVC

train_folder = 'testData'

train_set = []
train_y = []
for filename in os.listdir(train_folder):
	#female -1 and male - 0
	

	if(filename[-34] == '1'):
		train_y.append(1)
	else:
		train_y.append(0)
	filename = train_folder+'/'+filename
	train_set.append(cv2.imread(filename))

xTrain, xTest, yTrain, yTest = train_test_split(train_set, train_y, test_size = 0.2, random_state = 0)
epochs = 90
train_set = np.array(xTrain)
train_y  = np.array(yTrain)

test_set = np.array(xTest)
test_y  = np.array(yTest)

svm = SVC(kernel='rbf')

svm.fit(train_set,train_y)




pred = svm.predict(test_set)

print(accuracy_score(test_y, pred))



#loading the weights and then fitting the svm
from keras.models import model_from_json
import keras.losses
from keras.optimizers import SGD
import os 
import cv2
import numpy as np

train_folder = 'testData'

train_set = []
train_y = []
for filename in os.listdir(train_folder):
	#female -1 and male - 0
	

	if(filename[-34] == '1'):
		train_y.append(1)
	else:
		train_y.append(0)
	filename = train_folder+'/'+filename
	train_set.append(cv2.imread(filename))

xTrain, xTest, yTrain, yTest = train_test_split(train_set, train_y, test_size = 0.2, random_state = 0)

train_set = np.array(xTrain)
train_y  = np.array(yTrain)

# load json and create model
json_file = open('model3.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("model3.h5")
print("Loaded model from disk")




# evaluate loaded model on test data
loaded_model.compile(loss = 'hinge',optimizer = keras.optimizers.SGD(lr=0.002),metrics=['accuracy'])

model_feat = Model(inputs=loaded_model.input,outputs=loaded_model.get_layer('layer_f').output)
feat_train = model_feat.predict(train_set)
feat_test = model_feat.predict(test_set)

svm = SVC(kernel='rbf')

svm.fit(feat_train,train_y)

pred = svm.predict(TEST)

print(accuracy_score(TESTY,pred))

#load the svm model and directly predict
import numpy as np
import keras.utils
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers.normalization import BatchNormalization
from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten,Activation
from keras.layers import Conv2D,MaxPooling2D#use 2d convo layers because filter goes horizontal and vertical
from keras.activations import relu
import keras.losses
import pandas
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
import pickle
import os
import glob
import cv2
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from keras.optimizers import SGD
from sklearn.svm import SVC

directory = 't'

TEST = []
TESTY = [1,1,1,0,1,0,0,0]
for filename in os.listdir(directory):
	filename = directory+'/'+filename
	TEST.append(cv2.imread(filename))
	


TEST = np.array(TEST)
TESTY = np.array(TESTY)

json_file = open('model4.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model


score = loaded_model.evaluate(TEST, TESTY, verbose=0)
print("%s: %.2f%%" % (loaded_model.metrics_names[1], score[1]*100))

!ls

!unzip 'drive/My Drive/testData.zip'

from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive')

#predicting directly from the pickled file but gives an error
import numpy as np
import keras.utils
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers.normalization import BatchNormalization
from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten,Activation
from keras.layers import Conv2D,MaxPooling2D#use 2d convo layers because filter goes horizontal and vertical
from keras.activations import relu
import keras.losses
import pandas
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
import pickle
import os
import glob
import cv2
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from keras.optimizers import SGD
from sklearn.svm import SVC


train_folder = 'testData'

train_set = []
train_y = []
for filename in os.listdir(train_folder):
	#female -1 and male - 0
	

	if(filename[-34] == '1'):
		train_y.append(1)
	else:
		train_y.append(0)
	filename = train_folder+'/'+filename
	train_set.append(cv2.imread(filename))

xTrain, xTest, yTrain, yTest = train_test_split(train_set, train_y, test_size = 0.2, random_state = 0)
epochs = 90
train_set = np.array(xTrain)
train_y  = np.array(yTrain)

test_set = np.array(xTest)
test_y  = np.array(yTest)

filename = 'drive/My Drive/finalized_model.sav'
# load the model from disk
loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(test_set,test_y)
print(result)

import tensorflow as tf
tf.test.gpu_device_name()